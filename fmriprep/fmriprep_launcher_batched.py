#!/usr/bin/env python3
"""
Enhanced version of fmriprep_launcher.py with multi-subject batching support.

This allows processing multiple subjects per SLURM job, which can be more
efficient than one subject per job.
"""

import argparse
import math
from pathlib import Path
from typing import List, Optional

def create_subject_batches(subjects: List[str], subjects_per_job: int) -> List[List[str]]:
    """
    Group subjects into batches for processing.
    
    Args:
        subjects: List of subject IDs
        subjects_per_job: Number of subjects to process per job
        
    Returns:
        List of subject batches
    """
    if subjects_per_job <= 0:
        subjects_per_job = 1
        
    batches = []
    for i in range(0, len(subjects), subjects_per_job):
        batch = subjects[i:i + subjects_per_job]
        batches.append(batch)
    
    return batches

def write_batch_file(batch_file: Path, batches: List[List[str]]) -> None:
    """
    Write subject batches to file, one batch per line.
    
    Args:
        batch_file: Path to output file
        batches: List of subject batches
    """
    lines = []
    for batch in batches:
        # Write space-separated subjects on each line
        lines.append(" ".join(batch))
    
    batch_file.write_text("\n".join(lines) + "\n")
    print(f"Wrote {len(batches)} batch(es) to {batch_file}")
    print(f"  Each batch contains up to {len(batches[0])} subject(s)")

def create_batched_slurm_template(subjects_per_job: int = 1) -> str:
    """
    Create a SLURM template that handles multiple subjects per job.
    """
    template = """\
#!/usr/bin/env bash
#
# Auto-generated by fmriprep_launcher.py with batching
# Processing {subjects_per_job} subject(s) per job
#
#SBATCH --job-name={{job_name}}
#SBATCH --partition={{partition}}
#SBATCH --time={{time}}
#SBATCH --cpus-per-task={{cpus_per_task}}
{{mem_line}}#SBATCH --nodes=1
#SBATCH --array=0-{{array_max}}
#SBATCH --output={{log_dir}}/%x_%A_%a.out
#SBATCH --error={{log_dir}}/%x_%A_%a.err
{{account_line}}{{mail_line}}{{module_line}}

set -euo pipefail

# ===== User settings (auto-generated) =====
BIDS_DIR="{{bids}}"
OUT_DIR="{{out}}"
WORK_DIR="{{work}}"
FS_LICENSE="{{fs_license}}"
BATCH_FILE="{{batch_file}}"
RUNTIME="{{runtime}}"                  # singularity | fmriprep-docker | docker
CONTAINER="{{container}}"              # path to .sif or docker image:tag
OMP_THREADS="{{omp_threads}}"
NPROCS="{{nprocs}}"
MEM_MB="{{mem_mb}}"
EXTRA_FLAGS="{{extra_flags}}"
SKIP_BIDS_VAL="{{skip_bids_val}}"
OUTPUT_SPACES="{{output_spaces}}"
USE_AROMA="{{use_aroma}}"
CIFTI="{{cifti}}"
FS_RECONALL="{{fs_reconall}}"
USE_SYN_SDC="{{use_syn_sdc}}"

# ===== Derived settings =====
# Read subject batches (each line contains {subjects_per_job} space-separated subjects)
mapfile -t BATCHES < <(grep -v '^#' "$BATCH_FILE" | sed '/^$/d')
BATCH="${{BATCHES[$SLURM_ARRAY_TASK_ID]}}"
if [[ -z "$BATCH" ]]; then
  echo "No batch for index $SLURM_ARRAY_TASK_ID"; exit 1;
fi

# Parse subjects from batch (space-separated)
IFS=' ' read -ra SUBJECTS <<< "$BATCH"
echo "=== Processing ${{#SUBJECTS[@]}} subject(s) in this job ==="
for SUB in "${{SUBJECTS[@]}}"; do
  echo "  - $SUB"
done

# Build participant labels (remove sub- prefix)
LABELS=()
for SUB in "${{SUBJECTS[@]}}"; do
  LABELS+=("${{SUB#sub-}}")
done

mkdir -p "$OUT_DIR" "$WORK_DIR" "{{log_dir}}"

# Build CLI with multiple participant labels
CLI=(participant --participant-label "${{LABELS[@]}}" --nprocs "$NPROCS" --omp-nthreads "$OMP_THREADS" --mem-mb "$MEM_MB" --notrack)

if [[ "$SKIP_BIDS_VAL" == "1" ]]; then
  CLI+=(--skip-bids-validation)
fi
if [[ -n "$OUTPUT_SPACES" ]]; then
  CLI+=(--output-spaces $OUTPUT_SPACES)
fi
if [[ "$USE_AROMA" == "1" ]]; then
  CLI+=(--use-aroma)
fi
if [[ "$CIFTI" == "1" ]]; then
  CLI+=(--cifti-output 91k)
fi
if [[ "$FS_RECONALL" == "0" ]]; then
  CLI+=(--fs-no-reconall)
fi
if [[ "$USE_SYN_SDC" == "1" ]]; then
  CLI+=(--use-syn-sdc)
fi
if [[ -n "$EXTRA_FLAGS" ]]; then
  CLI+=($EXTRA_FLAGS)
fi

echo "=== Running fMRIPrep for batch $SLURM_ARRAY_TASK_ID on $HOSTNAME ==="
echo "Runtime: $RUNTIME"
echo "Container: $CONTAINER"
echo "Subjects: ${{SUBJECTS[@]}}"
echo "----------------------------------------------"

if [[ "$RUNTIME" == "singularity" ]]; then
  RT_BIN=$(command -v singularity || command -v apptainer)
  "$RT_BIN" run --cleanenv \\
    -B "$BIDS_DIR:/data:ro" \\
    -B "$OUT_DIR:/out" \\
    -B "$WORK_DIR:/work" \\
    -B "$FS_LICENSE:/opt/freesurfer/license.txt:ro" \\
    "$CONTAINER" \\
    /data /out "${{CLI[@]}}" --work-dir /work --fs-license-file /opt/freesurfer/license.txt

elif [[ "$RUNTIME" == "fmriprep-docker" ]]; then
  fmriprep-docker "$BIDS_DIR" "$OUT_DIR" "${{CLI[@]}}" --work-dir "$WORK_DIR" --fs-license-file "$FS_LICENSE"

elif [[ "$RUNTIME" == "docker" ]]; then
  docker run --rm \\
    -v "$BIDS_DIR:/data:ro" \\
    -v "$OUT_DIR:/out" \\
    -v "$WORK_DIR:/work" \\
    -v "$FS_LICENSE:/opt/freesurfer/license.txt:ro" \\
    "$CONTAINER" \\
    /data /out "${{CLI[@]}}" --fs-license-file /opt/freesurfer/license.txt --work-dir /work

else
  echo "Unknown runtime: $RUNTIME" >&2; exit 2
fi
"""
    return template.format(subjects_per_job=subjects_per_job)

def estimate_resources_for_batch(subjects_per_job: int, 
                                base_mem_per_subject: int = 8000,
                                base_cpus_per_subject: int = 4) -> tuple:
    """
    Estimate resource requirements for processing multiple subjects.
    
    Args:
        subjects_per_job: Number of subjects per job
        base_mem_per_subject: Base memory per subject in MB
        base_cpus_per_subject: Base CPUs per subject
        
    Returns:
        (suggested_cpus, suggested_mem_mb)
    """
    # fMRIPrep can share some resources between subjects
    # but not linearly - there's some overhead reduction
    if subjects_per_job == 1:
        return base_cpus_per_subject, base_mem_per_subject
    
    # Approximate scaling: 
    # - Memory: first subject needs full amount, additional subjects need ~70%
    # - CPUs: can be shared more efficiently
    mem_mb = base_mem_per_subject + (subjects_per_job - 1) * int(base_mem_per_subject * 0.7)
    cpus = min(base_cpus_per_subject * subjects_per_job, 
               max(base_cpus_per_subject * 2, base_cpus_per_subject + subjects_per_job))
    
    return cpus, mem_mb

def main():
    """Example of how batching would work"""
    
    # Example subjects
    subjects = [f"sub-{i:02d}" for i in range(1, 11)]  # 10 subjects
    
    print("=" * 60)
    print("fMRIPrep Multi-Subject Batching Examples")
    print("=" * 60)
    
    for subjects_per_job in [1, 2, 3, 5]:
        print(f"\nBatching with {subjects_per_job} subject(s) per job:")
        print("-" * 40)
        
        batches = create_subject_batches(subjects, subjects_per_job)
        cpus, mem = estimate_resources_for_batch(subjects_per_job)
        
        print(f"Total subjects: {len(subjects)}")
        print(f"Number of jobs: {len(batches)}")
        print(f"Suggested resources per job:")
        print(f"  CPUs: {cpus}")
        print(f"  Memory: {mem} MB ({mem/1000:.1f} GB)")
        
        print("\nBatch distribution:")
        for i, batch in enumerate(batches):
            print(f"  Job {i}: {', '.join(batch)}")
    
    print("\n" + "=" * 60)
    print("Benefits of multi-subject batching:")
    print("- Fewer jobs in SLURM queue")
    print("- Better resource utilization")
    print("- Shared template/atlas loading")
    print("- Reduced overall runtime for small datasets")
    print("\nConsiderations:")
    print("- Longer individual job runtime")
    print("- If one subject fails, whole job may fail")
    print("- Need more memory and CPUs per job")
    print("- Best for datasets with <20 subjects")

if __name__ == "__main__":
    main()